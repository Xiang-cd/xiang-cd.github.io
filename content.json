{"posts":[{"title":"Emu3-practice","text":"æœ€è¿‘åŒ—äº¬æ™ºæºæ”¾äº†ä¸€ä¸ªæ¨¡å‹å«åšemu3ï¼Œæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ï¼Œæ°å·§æœºå™¨å­¦ä¹ è¯¾ç¨‹éœ€è¦æœ‰ä¸ªprojectï¼Œç„¶åå°±æ‰“ç®—å¾®è°ƒä¸€ä¸‹ï¼Œä½“éªŒä¸€ä¸‹AR model çš„é­…åŠ›ã€‚ å°±causal transformeræœ¬èº«å…¶å®å¹¶ä¸å¤æ‚ï¼Œä½†æ˜¯æ¯”è¾ƒå¤æ‚æˆ–è€…æˆ‘ä¸å¤ªç†Ÿæ‚‰çš„åº”è¯¥æ˜¯tokenizerï¼Œç‰¹åˆ«æ˜¯è§†è§‰tokenizeræ˜¯å¦‚ä½•ç»„ç»‡çš„ï¼Œç”Ÿæˆè¿‡ç¨‹ä¸­å¦‚ä½•ä¿è¯å›¾åƒè§„æ ¼ï¼Œå„ç±»ç‰¹æ®Štokençš„ä½œç”¨ï¼ŒARæ¨¡å‹çš„CFGæ˜¯å¦‚ä½•åœ¨ä»£ç å±‚é¢å®ç°çš„ç­‰é—®é¢˜ï¼Œæ‰€ä»¥è¿™ç¯‡åšå®¢å°±æ˜¯å¸¦ç€é—®é¢˜æ¥å¯»æ‰¾ç­”æ¡ˆï¼Œå¹¶è®°å½•ä¸‹æ¥ã€‚ emu3çš„vision tokenizervqvaeæœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªvqvaeï¼Œä½†æ˜¯è¦ä½¿å¾—vaeèƒ½å¤Ÿç¼–è§£ç è§†é¢‘ï¼ŒåŒæ—¶å¯¹è§†é¢‘åœ¨æ—¶é—´ç»´åº¦ä¸Šçš„å‹ç¼©åšåˆ°4ã€‚å¯¹äºåŸå§‹çš„2Dvaeçš„æ”¹è¿›ç‚¹åœ¨äºï¼Œå°†res blockä¸­çš„2D convæ¢æˆcausal 3Dconvï¼Œä½†æ˜¯è¿™äº›3Dconvå¹¶ä¸åŒæ—¶å‹ç¼©æ—¶é—´ç»´åº¦ï¼Œåªåœ¨2Dç»´åº¦å®Œæˆå‹ç¼©ä¹‹åå†å•ç‹¬è¿›è¡Œä¸¤æ¬¡çš„æ—¶é—´ç»´åº¦å‹ç¼©ï¼Œè§£ç åˆ™æ˜¯å…ˆæ‰©å±•æ—¶é—´ç»´åº¦ï¼Œç„¶åå†ä¸Šé‡‡æ ·ç©ºé—´ç»´åº¦ã€‚å¯¹äºå›¾ç‰‡çš„å¤„ç†ï¼Œæ˜¯å°†å›¾ç‰‡åœ¨æ—¶é—´ç»´åº¦é‡å¤å››æ¬¡ä½œä¸ºè§†é¢‘è¿›è¡Œå‹ç¼©æˆ–è€…é€†å‹ç¼©ï¼Œ é‡æ„ååªå–ç¬¬ä¸€å¸§ã€‚ image tokenå’Œtext tokençš„è”åˆå¤„ç†è¿™é‡Œæˆ‘æƒ³å¼„æ˜ç™½çš„æ˜¯ï¼Œvision tokenå’Œtext tokenæ˜¯å¦‚ä½•share code bookçš„ã€‚åœ¨emu3ä¸­ï¼Œä¸»è¦é€šè¿‡Emu3Processorè¿™ä¸ªç±»æ¥å®ç°ï¼Œåˆå§‹åŒ–ä¼ å…¥å›¾ç‰‡é¢„å¤„ç†å™¨ï¼Œvqvaeä»¥åŠtext tokenizerã€‚ 1processor = Emu3Processor(image_processor, image_tokenizer, tokenizer) å…¶ä¸­æœ€é‡è¦çš„å‡½æ•°æ˜¯ï¼š 12345678910111213visual_template=(\"&lt;|visual token {token_id:0&gt;6d}|&gt;\", r\"&lt;\\|visual token (\\d+)\\|&gt;\")def to_imgstr(self, image_tokens): image_tokens = image_tokens.cpu().numpy().tolist() image_token_str = [ [ self.visual_template[0].format(token_id=token_id) for token_id in token_row ] for token_row in image_tokens ] image_row_str = [\"\".join(token_row) for token_row in image_token_str] imgstr = self.tokenizer.eol_token.join(image_row_str) return imgstr ä»¥ä¸Šå‡½æ•°è¯´æ˜ç™½äº†ä¸¤ä¸ªé—®é¢˜ï¼š è§†è§‰tokenåˆ°æ–‡æœ¬tokençš„è½¬åŒ–ã€‚è§†è§‰tokenä¼šè¢«è½¬åŒ–ä¸ºâ€™&lt;|visual token 000000|&gt;â€™ è¿™æ ·çš„æ–‡æœ¬tokenï¼Œè¿™åœ¨æ–‡æœ¬tokenizerä¸­ç›¸å½“äºç¬¬151854ä¸ªtokenï¼Œä¾æ¬¡å¢é•¿ï¼Œä¹Ÿå°±æ˜¯å‰151853ä¸ªæ˜¯æ™®é€šæœ¬æ–‡tokenï¼Œåé¢çš„ä¾æ¬¡æ˜¯è§†è§‰tokenã€‚å®Œæˆäº†tokençš„æ˜ å°„ã€‚ è§†è§‰tokençš„ç¼–æ’ã€‚å¯è§ï¼Œå›¾åƒçš„ç¼–ç æ˜¯é€šè¿‡æ¢è¡Œæ¥è¿›è¡Œçš„ï¼Œæ²¡æœ‰å¯¹å›¾åƒtokenåš2Dçš„ä½ç½®ç¼–ç ï¼Œè¿™å’Œæ–‡ç« è¡¨è¿°ä¸€è‡´ã€‚ å¦‚ä½•ä¿è¯å›¾åƒç”Ÿæˆè§„æ ¼è¿™é‡Œæˆ‘æƒ³è§£å†³çš„é—®é¢˜æ˜¯ï¼ŒARæ¨¡å‹ç”Ÿæˆtokenæ˜¯ä¼°è®¡tokençš„æ¦‚ç‡åˆ†å¸ƒï¼Œè¿™æ„å‘³ç€å¯¹äºä¸€ä¸ª64X64çš„å›¾ç‰‡ç”Ÿæˆè¿‡ç¨‹ï¼Œæ¨¡å‹å¯èƒ½åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ç¬¬ä¸€è¡Œç”Ÿæˆäº†64ä¸ªvisual tokenï¼Œç¬¬äºŒè¡Œç”Ÿæˆäº†67ä¸ªvisual tokenï¼Œè¿™ä¼šå¯¼è‡´å›¾ç‰‡å¹¶ä¸è§„æ ¼ã€‚ å¯¹æ­¤ï¼Œemu3çš„è§£å†³æ–¹æ¡ˆæ˜¯çº¦æŸå½“å‰tokenç”Ÿæˆçš„èŒƒå›´ï¼Œä¾‹å¦‚åˆ°äº†ç¬¬65ä¸ªtokenï¼Œåˆ™ä¸¥æ ¼é™åˆ¶åªèƒ½ç”Ÿæˆæ¢è¡Œç¬¦å·ï¼Œå…·ä½“çš„ä»£ç å®ç°æ˜¯é€šè¿‡ä¼ é€’ä¸€ä¸ªPrefixConstrainedLogitsProcessorï¼Œå¹¶å¯¹è¿™ä¸ªç±»ä¼ é€’ä¸€ä¸ªåˆ¤æ–­ç”ŸæˆçŠ¶æ€çš„å‡½æ•°ã€‚ 12345constrained_fn = processor.build_prefix_constrained_fn(h, w)PrefixConstrainedLogitsProcessor( constrained_fn , num_beams=1,) æœ€æ ¸å¿ƒçš„åˆ¤æ–­é€»è¾‘åœ¨ï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Emu3PrefixConstrainedLogitsHelper: def __init__( self, height, width, img_token, eoi_token, eos_token, eol_token, eof_token, pad_token, visual_tokens, ): self.height = height self.width = width self.img_token = img_token self.eoi_token = eoi_token self.eos_token = eos_token self.eol_token = eol_token self.eof_token = eof_token self.pad_token = pad_token self.visual_tokens = visual_tokens self.offset_cache = {} def __call__(self, batch_id, input_ids): if batch_id not in self.offset_cache: position = torch.nonzero(input_ids == self.img_token, as_tuple=True)[0][0] self.offset_cache[batch_id] = position height = self.height[batch_id] if self.height.shape[0] &gt; 1 else self.height[0] width = self.width[batch_id] if self.width.shape[0] &gt; 1 else self.width[0] offset = input_ids.shape[0] - self.offset_cache[batch_id] height = height.to(offset.device) width = width.to(offset.device) if offset % (width + 1) == 0: return (self.eol_token, ) elif offset == (width + 1) * height + 1: return (self.eof_token, ) elif offset == (width + 1) * height + 2: return (self.eoi_token, ) elif offset == (width + 1) * height + 3: return (self.eos_token, ) elif offset &gt; (width + 1) * height + 3: return (self.pad_token, ) else: return self.visual_tokens å¯è§çš„ï¼Œè¿™ä¸ªprefixconstrainå¯¼è‡´äº†å½“å‰çš„ç”Ÿæˆç­–ç•¥åªèƒ½ç”Ÿæˆä¸€å¼ å›¾ç‰‡ã€‚ æ ¹æ®æ–‡ç« å’Œåˆæ­¥çš„ä»£ç åˆ¤æ–­ï¼Œæœ€ç»ˆçš„tokenæ’åˆ—æƒ…å†µåº”å½“å¦‚ä¸‹ï¼š 1234567891011121314151617181920[BOS] {caption text} // caption text tokens [SOV{boi}] \"{H}*{W}\" // h * w are meta info tokens [SOT{img_token}] [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] // end of line [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] // vs are vision tokens [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] [EOF] // end of frame [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] // end of line [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] // vs are vision tokens [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] [vs] [vs] [vs] [vs] [vs] [vs] [EOL{eol}] [EOF] // end of frame [EOV{eoi}] [EOS] ä¸ºäº†èƒ½å¤Ÿè®©æ¨¡å‹å®ç°å¤šå¸§çš„ç”Ÿæˆï¼Œå¯ä»¥ç®€å•å¯¹constrainåšç®€å•çš„ä¿®æ”¹ï¼Œå¹¶å¢åŠ æ–°çš„å¸§æ•°é‡çš„è¶…å‚ã€‚ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Emu3PrefixConstrainedLogitsHelper: def __init__( self, height, width, img_token, eoi_token, eos_token, eol_token, eof_token, pad_token, visual_tokens, num_frame=1, ): self.height = height self.width = width self.img_token = img_token self.eoi_token = eoi_token self.eos_token = eos_token self.eol_token = eol_token self.eof_token = eof_token self.pad_token = pad_token self.visual_tokens = visual_tokens self.num_frame = num_frame self.offset_cache = {} self.frame_index_cache = {} def __call__(self, batch_id, input_ids): if batch_id not in self.offset_cache: position = torch.nonzero(input_ids == self.img_token, as_tuple=True)[0][0] self.offset_cache[batch_id] = position self.frame_index_cache[batch_id] = 0 height = self.height[batch_id] if self.height.shape[0] &gt; 1 else self.height[0] width = self.width[batch_id] if self.width.shape[0] &gt; 1 else self.width[0] offset = input_ids.shape[0] - self.offset_cache[batch_id] height = height.to(offset.device) width = width.to(offset.device) if (offset - self.frame_index_cache[batch_id]) % (width + 1) == 0: return (self.eol_token, ) elif offset % ((width + 1) * height + 1) == 0: self.frame_index_cache[batch_id] += 1 return (self.eof_token, ) elif offset == ((width + 1) * height + 1) * self.num_frame + 1: return (self.eoi_token, ) elif offset == ((width + 1) * height + 1) * self.num_frame + 2: return (self.eos_token, ) elif offset &gt; ((width + 1) * height + 1) * self.num_frame + 3: return (self.pad_token, ) else: return self.visual_tokens å¦‚ä½•è¿›è¡ŒCFGåœ¨æ‰©æ•£æ¨¡å‹ä¸­ï¼Œclassifier free guidance(CFG)å°±æ˜¯å¯¹äºæ¨¡å‹çš„æ¡ä»¶å’Œæ— æ¡ä»¶é¢„æµ‹è¿›è¡Œçº¿æ€§åŠ æƒå¤–æ¨ï¼Œä½¿å¾—æ¨¡å‹æœç€æ¡ä»¶æ–¹å‘è¿›è¡Œå‰è¿›ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªè¶…å‚guidance scaleï¼Œå…·ä½“å…¬å¼å¦‚ä¸‹ï¼š 1new_pred = pred_uncond + guidance_scale * (pred_cond - pred_uncond) è¿™åœ¨æ‰©æ•£æ¨¡å‹ä¸­èƒ½å¤Ÿæ˜¾è‘—æé«˜ç”Ÿæˆè´¨é‡ï¼Œåœ¨ARæ¨¡å‹ç”¨äºè§†è§‰ç”Ÿæˆä¹Ÿè¢«è¯æ˜èƒ½å¤Ÿæé«˜ç”Ÿæˆè´¨é‡ã€‚åœ¨ARæ¨¡å‹ä¸­ï¼Œæ¯”è¾ƒé‡è¦çš„æ˜¯åœ¨å“ªä¸ªç©ºé—´è¿›è¡ŒCFGï¼Œæ˜¯åœ¨logitsï¼ˆæœªå½’ä¸€åŒ–ï¼‰ï¼Œè¿˜æ˜¯åœ¨å½’ä¸€åŒ–ï¼ˆsoftmaxï¼‰ä¹‹åçš„ç©ºé—´ï¼Œè¿˜æ˜¯åœ¨å¯¹æ•°å½’ä¸€åŒ–ï¼ˆlog_softmax)ç©ºé—´ã€‚ åœ¨emu3çš„ä»£ç ä¸­ï¼Œå®ç°CFGçš„ä»£ç ä½äºUnbatchedClassifierFreeGuidanceLogitsProcessorè¿™ä¸ªç±»ä¸­ã€‚æ ¸å¿ƒä»£ç å¦‚ä¸‹ï¼š 12345678910def __call__(self, input_ids, scores): scores = torch.nn.functional.log_softmax(scores, dim=-1) if self.guidance_scale == 1: return scores logits = self.get_unconditional_logits(input_ids) unconditional_logits = torch.nn.functional.log_softmax(logits[:, -1], dim=-1) scores_processed = self.guidance_scale * (scores - unconditional_logits) + unconditional_logits return scores_processed å¯è§ï¼ŒCFGåœ¨å¯¹æ•°å½’ä¸€åŒ–ç©ºé—´è¿›è¡Œã€‚","link":"/blog/Emu3-practice/"},{"title":"My New Post","text":"This is an test blog post.code test1print(\"Hello, world!\") math testtest math , this was enabled by: 1npm install hexo-filter-mathjax set _config.yml as follows: 1234567891011mathjax: tags: all # or 'ams' or 'all' single_dollars: true # enable single dollar signs as in-line math delimiters cjk_width: 0.9 # relative CJK char width normal_width: 0.6 # relative normal (monospace) width append_css: true # add CSS to pages rendered by MathJax every_page: true # if true, every page will be rendered by MathJax regardless the `mathjax` setting in Front-matter packages: # extra packages to load extension_options: {} # you can put your extension options here # see http://docs.mathjax.org/en/latest/options/input/tex.html#tex-extension-options for more detail test quote list item 1 list item 2","link":"/blog/My-New-Post/"},{"title":"Sora authors","text":"å‰è¨€Soraå¯¹äºç”Ÿæˆæ¨¡å‹é¢†åŸŸçš„impact, è¿œå¤§äºä¸¤å¹´å‰çš„Dalle2, å› ä¸ºDalle2æ˜¯å°†ä¸€ä¸ªé—®é¢˜çš„æ€§èƒ½æé«˜ä¸€ä¸ªå±‚æ¬¡, ä»ä¸å¯ç”¨å˜ä¸ºå¯ç”¨ã€‚è€ŒSoraåˆ™æ˜¯å‘ä¸–äººå±•ç¤ºä¸€ä»¶äº‹æƒ…æ˜¯å¦‚ä½•ä»ä¸å¯èƒ½åˆ°å¯èƒ½çš„ã€‚å…¶å®ä»å¾ˆå¤šäººçš„æŠ€æœ¯åˆ†æè§’åº¦çœ‹, SoraèƒŒåçš„æŠ€æœ¯å¹¶ä¸å¤æ‚, æˆ‘ç›¸ä¿¡å›½å†…çš„å…¬å¸ä¹Ÿèƒ½å¤Ÿåœ¨ä¸€å®šçš„æ—¶é—´å†…å¤ç°å‡ºsora, ä¸ºä»€ä¹ˆè¯´å›½å†…å…¬å¸èƒ½å¤ç°, å› ä¸ºä»–ä»¬å·²ç»çœ‹åˆ°äº†ä¸€ä»¶äº‹æƒ…æ˜¯å¯èƒ½çš„, å›½å†…GPTç™¾æ¨¡å¤§æˆ˜çš„ç°è±¡ä¹Ÿæ˜¯, åªæœ‰åœ¨OpenAIè¯æ˜äº†ä¸€ä»¶äº‹æƒ…æ˜¯å¯è¡Œ, å›½å†…çš„å…¬å¸æ‰ä¸€çªèœ‚çš„ä¸Šå»åšã€‚ æ‰€ä»¥ä»è¿™ä¸ªè§’åº¦çœ‹, æœ€é¡¶å°–çš„æŠ€æœ¯é—®é¢˜, ä¸æ˜¯æŠ€æœ¯æœ¬èº«, è€Œæ˜¯ä¿¡å¿µé—®é¢˜, ä¸€ç§ç†æ€§è€Œåšå®šçš„ä¿¡å¿µã€‚ è€Œä¸ºä»€ä¹ˆOpenAIçš„å›¢é˜Ÿèƒ½å¤Ÿæœ‰è¿™æ ·çš„ä¿¡å¿µå‘¢, å¦‚ä½•åœ¨æœªçŸ¥çš„æƒ…å†µä¸‹æ¢ç´¢æœªçŸ¥, æœ€åå‘ç°å®è—? æˆ‘æƒ³è¿™ä¸€å®šå’Œè¿™ç¾¤äººæœ‰å…³ç³», çœ‹æ¸…æ¥šè¿™ç¾¤äººæœ‰ä»€ä¹ˆæ ·çš„ç‰¹è´¨, å¯¹æœªæ¥ä¸ªäººå‘å±•è§„åˆ’, æŠ€æœ¯å…¬å¸å¯»æ‰¾æœ‰æ½œåŠ›çš„åˆ›æ–°äººæ‰, æ€»ç»“ç¾å›½åœ¨AIé¢†åŸŸé¢†å…ˆåœ°ä½æ˜¯å¦‚ä½•å½¢æˆçš„, éƒ½æœ‰ä¸€å®šçš„ç›Šå¤„, æ‰€ä»¥è¿™ç¯‡åšå®¢ä¸»è¦å°±æ˜¯é€šè¿‡åˆ†æsoraçš„ä½œè€…ä»¬, æ¥çœ‹çœ‹æœ‰ä»€ä¹ˆå¯å‘ã€‚ 1. Tim Brooks Google Scholar ä¸»é¡µ github linked In åšå£«: 2019.8-2023.1(å…±å››å¹´), PhD at Berkeley AI Research advised by Alyosha Efros åšå£«è®ºæ–‡ å­¦å£«: CMU, 2013-2017ã€‚ ä»åšå£«å¹´é™ä¸Šæ¥çœ‹, åº”è¯¥æ˜¯è¯»äº†ç¡•å£«çš„, ä½†æ˜¯ç¡•å£«å­¦å†å¹¶æ²¡æœ‰å†™åœ¨é¢†è‹±ä¸­, çœ‹èµ·æ¥åº”è¯¥æ˜¯gapäº†,å¦åˆ™åº”è¯¥æœ‰æ—©äº2019å¹´çš„æ–‡ç«  , è¿™æˆ–è®¸æ˜¯æœ‰æ„æ€çš„ç‚¹ã€‚ ä»å­¦å£«è§’åº¦çœ‹, åº”è¯¥åœ¨1994å¹´å‡ºç”Ÿã€‚ åœ¨2019å¹´å°±æœ‰ä¸¤ç¯‡CVPR oral, ä¸»è¦ä»äº‹å›¾ç›¸å…³å¤„ç†(è¶…åˆ†è¾¨ç‡, åœ¨Google), ç”Ÿæˆæ¨¡å‹(GAN, åœ¨NVIDIA)ã€‚æ˜æ˜Ÿå·¥ä½œæ˜¯instrucPix2Pix, è¿™ç¯‡æ–‡ç« æœ€å¤§çš„äº®ç‚¹åœ¨äºåˆ©ç”¨GPT3è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®, è¿™æ ·çš„æ€æƒ³åœ¨2022chatgptå‡ºç°ä»¥å‰æ˜¯éå¸¸é¢†å…ˆçš„ã€‚åŒæ—¶åœ¨éšåä»äº‹äº†Dalle3å’ŒSoraçš„å·¥ä½œ, è¿˜å‚ä¸äº†GPT4æŠ€æœ¯æŠ¥å‘Šã€‚å¯ä»¥è¯´åœ¨OpenAIéƒ½è´Ÿè´£åˆ°äº†æ¯”è¾ƒæ ¸å¿ƒçš„å·¥ä½œã€‚ ä»æ¨ç‰¹çœ‹, ä»–è‡ªå·±ä¹Ÿå¯¹è‡ªå·±Soraçš„å·¥ä½œéå¸¸æ»¡æ„, ç–¯ç‹‚è½¬å‘Soraç”Ÿæˆçš„è§†é¢‘ã€‚ ä»ä½“æ¥è¯´, ä»–çš„æ±‚å­¦ç”Ÿæ¶¯è¿˜æ˜¯æ¯”è¾ƒæ¼«é•¿çš„, è¯»äº†åå¹´çš„ä¹¦, åœ¨æœ¬ç§‘å’Œgapæˆ–è€…ç¡•å£«é˜¶æ®µè¿˜æ²¡æœ‰å¾ˆå¤šçš„äº§å‡ºã€‚ä»å½±å“åŠ›æ¥çœ‹, åšå£«ç”ŸåˆæœŸçš„ä½œå“ä¹Ÿæ²¡æœ‰å¾ˆæ˜¾è‘—, ä½†æ˜¯ä»–å·¥ä½œä¸€ä¸ªå¾ˆé‡è¦çš„ç‰¹ç‚¹å°±æ˜¯è´¨é‡é«˜(ä¸¤ç¯‡oral), å…¶æ¬¡å°±æ˜¯ä»–çš„å·¥ä½œç´§å¯†çš„å’Œå·¥ä¸šç•Œ, ç‰¹åˆ«æ˜¯å¤§å‚ç»“åˆ; å‡ºè‰²çš„å¤§å‚ç»å†, å¹¶ä¸”åœ¨æ¯ä¸€æ®µå¤§å‚çš„ç»å†ä¸­åšå‡ºç›¸å…³çš„å·¥ä½œ, è€Œéåªæ˜¯ç»™å¤§å‚æ‰“å·¥, æˆ‘æƒ³è¿™ä¸€ç‚¹æ˜¯éœ€è¦å¾ˆå¼ºmotivationçš„ã€‚ä»–èµ·é£çš„é˜¶æ®µå°±æ˜¯ç§¯æåˆ©ç”¨OpenAIçš„GPTèµ„æº, åŒæ—¶æœ‰ç€å…ˆè¿›çš„åˆæˆæ•°æ®æ€æƒ³, å¹¶ä»˜è¯¸å®è·µ, æˆ‘è§‰å¾—è¿™æ ·çš„æ€æƒ³ä¹Ÿä½“ç°åœ¨äº†Soraçš„ç”Ÿæˆæ¨¡æ‹Ÿå™¨ç±»ä¼¼é£æ ¼çš„è§†é¢‘çš„è¿¹è±¡ä¸­ã€‚ å…¶å®åˆæˆæ•°æ®è¿™ä¸ªè¯é¢˜ä¸€ç›´åœ¨è¢«ä½¿ç”¨, ç‰¹åˆ«æ˜¯åœ¨è¯­è¨€æ¨¡å‹é¢†åŸŸ, ä½†æ˜¯çœŸæ­£å°†å…¶ç”¨åœ¨å›¾åƒè§†é¢‘ç”Ÿæˆé¢†åŸŸå¹¶æŠŠä¸€ä¸ªä¸œè¥¿ç‹ ç‹ çš„è°ƒwork, éƒ½æ˜¯ä¸å®¹æ˜“çš„ã€‚ å…¶å®å¯¹äºä¸€èˆ¬çš„åšå£«ç”Ÿè€Œè¨€, åªè¦æ•°æ®ä¸æ˜¯å¼€æºçš„, å°±ç«‹é©¬è¢«éš¾ä½äº†, è‡ªå·±ä¹Ÿä¸æ„¿æ„å»å¤ç°æ•°æ®çš„å¤„ç†, æ›´åˆ«æè‡ªå·±å–åˆ›é€ æ–°çš„æ•°æ®, è¿™äº›å·¥ä½œå¾ˆè„, ä½†æ˜¯å´ç›´æ¥å½±å“ä¸€äº›äº‹æƒ…èƒ½ä¸èƒ½å¼€å±•, æˆ‘è§‰å¾—æ”¾ä½è‡ªå·±çš„èº«ä½, è®¤çœŸæŠŠå·¥ä½œåšå¥½è¿™æ ·çš„å¿ƒæ€å’Œæ¯…åŠ›éƒ½æ˜¯ååˆ†éš¾å¾—çš„ã€‚ 2. Bill Peebles Google Scholar ä¸»é¡µ github åšå£«è®ºæ–‡ åšå£«: 2019.8-2023.1(å…±å››å¹´), Berkeley AI Research advised by Alyosha Efros. å­¦å£«: undergrad at MIT where I was advised by Antonio Torralba. ä»åšå£«å¹´é™ä¸Šçœ‹, åº”è¯¥åœ¨1995å¹´å·¦å³å‡ºç”Ÿã€‚ æ‰€æœ‰çš„å·¥ä½œ, ä¸æ˜¯Oralå°±æ˜¯Spotlight, åšå£«æœŸé—´ä¸€å…±6ç¯‡å·¥ä½œ, å…¶ä¸­ä¸€ä½œä»…ä¸¤ç¯‡ã€‚ä¸»è¦ä¸“æ³¨äºç”Ÿæˆæ¨¡å‹, åšå£«æœŸé—´æ›¾åœ¨FAIR, Adobe, NVIDIAå®ä¹ ã€‚ Tim Brookså’ŒBill Peeblesæœ‰å¤šæ¬¡åˆä½œ, å…¶ä¸­æœ‰ä¸€ç¯‡æ¯”è¾ƒæœ‰æ„æ€çš„æ˜¯Learning to learn with generative models of neural network checkpoints, åˆ©ç”¨ç”Ÿæˆæ¨¡å‹ç”Ÿæˆç¥ç»ç½‘ç»œçš„å‚æ•°, è¿™å¯ä»¥ç†è§£ä¸ºä¸€ç§meta learning, è™½ç„¶è¿™ç¯‡æ–‡ç« æ²¡æœ‰æŠ•ç¨¿å’Œä¸­ç¨¿, ä½†æ˜¯èƒŒåçš„æ¢ç´¢å’Œå°è¯•è¿˜æ˜¯æ¯”è¾ƒæœ‰æ„æ€çš„, ä½“ç°å‡ºäº†ä»–ä»¬æ•¢æƒ³æ•¢åšçš„ç²¾ç¥ã€‚æˆ‘è§‰å¾—åŒæ ·çš„, ä¸°å¯Œçš„å¤§å‚ç»å†å’Œèµ„æº, æ‰å®çš„å·¥ä½œ, æ•¢æƒ³æ•¢å¹², è¿™äº›éƒ½éå¸¸é‡è¦ã€‚ æˆ‘è§‰å¾—åè§‚æˆ‘è‡ªå·±, æœ‰æ—¶å€™å‚ä¸çš„äº‹æƒ…è¿‡å¤š, ä¸ºäº†è‡ªå·±å¿™è€Œå¿™, æ²¡æœ‰æ·±åˆ»æ€è€ƒè‡ªå·±ç ”ç©¶çš„åŠ¨æœºå’Œæ„ä¹‰, æœ‰æ—¶å€™æœ‰æƒ³æ³•å´ä¸æ•¢å¤§èƒ†çš„åšå‡ºæ¥, å¤§èƒ†çš„å»æƒ³åŠæ³•åš, æ²¡æœ‰å°è¯•å»å¤§å‚è·å–æ›´å¤šçš„èµ„æº, è¿™äº›æˆ‘è§‰å¾—å’Œä»–ä»¬è¿˜æ˜¯æœ‰é‡è¦çš„å·®è·ã€‚ 3. Connor Holmes Google Scholar æ¨ç‰¹ linked In åšå£«: 2017-2020, Colorado School of Mines, HPC å­¦å£«: 2013-2017, Colorado School of Mines, EE æ˜¯Soraçš„system leader, ä¸»è¦ä¼˜åŒ–å¤§è§„æ¨¡è®­ç»ƒå’Œæ¨ç†çš„, çœ‹å¾—å‡ºæ˜¯åšç³»ç»Ÿå‡ºèº«çš„, æ›¾åœ¨å¾®è½¯å®ä¹ å’Œå·¥ä½œ, ä¸»è¦å‚ä¸DeepSpeedçš„ç›¸å…³å·¥ä½œã€‚ç³»ç»Ÿç›¸å…³çš„ä½œå“éå¸¸å¤š, ä¸€å¹´èƒ½æœ‰äº”å…­ç¯‡ã€‚åšè¿‡å›¾ç›¸å…³çš„é«˜æ€§èƒ½è®¡ç®—, RNN gpuä¼˜åŒ–, GPUå¹¶è¡ŒDFS, Data efficient training of LLMã€‚åœ¨é«˜æ€§èƒ½é¢†åŸŸè¿˜æ˜¯æœ‰åŠŸåº•çš„ã€‚ ç³»ç»Ÿçš„ä¼˜åŒ–å¯¹äºæ¨¡å‹çš„è®­ç»ƒ, ç‰¹åˆ«æ˜¯æˆæœ¬çš„èŠ‚çº¦æœ‰éå¸¸é‡è¦çš„ä½œç”¨, ä½†æ˜¯è¿™å†³å®šçš„æ˜¯æˆæœ¬å’Œå®ç°æ—¶é—´ï¼Œè¿™æˆ–è®¸å¯¹äºä»–åˆšè¿›å…¥openAIå‡ ä¸ªæœˆä¹‹å†…å°±æå‡ºSoraæ˜¯ä»–å·¥ä½œå®åŠ›çš„è¯æ˜ã€‚ 4. Will DePueæ³¨æ„, è¿™æ˜¯ä¸€ä½å¤§ä½¬ ä¸»é¡µ linked in æ¨ç‰¹ github å­¦å£«: University of Michigan, é€€å­¦ä¸­â€¦.. é«˜ä¸­: Geffen Academy of UCLA å½“è¿‡ä¹ä¸ªæœˆçš„CEO, å·¥ç¨‹èƒ½åŠ›è¶…å¼º, å·¥ç¨‹èƒ½åŠ›å¼ºåœ¨ä½•å¤„? FIGMA-OS ä½¿ç”¨figmaæ„å»ºçš„8bitè®¡ç®—æœº WebGPT, ä¸¤ä¸ªç¤¼æ‹œå†™å®Œäº†, è·å¾—äº†4kçš„github star Hyperlocal, æ„å»ºåŸºäºè“ç‰™çš„åˆ†å¸ƒå¼ç‚¹å¯¹ç‚¹é€šä¿¡ç³»ç»Ÿ DeepResearch, æ•°æ®åˆ†æå’Œå¯è§†åŒ–ç³»ç»Ÿ Built the first Redstone computer only using pistons. ç¬¬ä¸€ä¸ªçº¢çŸ³è®¡ç®—æœº, æœ‰ç‚¹çŒ›ã€‚ åœ¨OpenAI åšè¿‡è¶Šç‹±å’Œæç¤ºæ³¨å…¥ç¼“è§£ã€è‡ªå®šä¹‰æ¨¡å‹ã€æ¨¡å‹èƒ½åŠ›è¯„ä¼°ã€APIå¾®è°ƒç­‰å·¥ä½œ, è¿™éƒ¨åˆ†å·¥ä½œå¯èƒ½ä¸æ˜¯å¾ˆå’Œè®­ç»ƒå’Œè®¾è®¡ç›¸å…³, ç¡®å®ä¹Ÿå’Œå·¥ç¨‹å¾ˆç›¸å…³ã€‚ ä»–è¯´: I find them restrictive: my most â€œhard skillâ€ is that I am the fastest and most curious learner Iâ€™ve ever met. å­¦ä¹ èƒ½åŠ›å¾ˆå¼º, å­¦ä¹ é€Ÿåº¦å¾ˆå¿«, è¿™ä¸€åˆ‡ä¹Ÿä½“ç°åœ¨ä»–çš„å·¥ç¨‹èƒ½åŠ›ä¸­ã€‚äººä¹Ÿå¾ˆæƒ³å¾—å¼€OpenAIè®©ä»–é€€å­¦å°±é€€å­¦, åšæŒåšè‡ªå·±æ„Ÿå…´è¶£çš„äº‹æƒ…, è¿™æ ·çš„äººæ‰çš„åŸ¹å…»å…¶å®æ˜¯å¾ˆéš¾å¾—çš„, æˆ‘è§‰å¾—æˆ‘ä»¬æˆ–å¤šæˆ–å°‘éƒ½è¢«ä¸€äº›å¤§å®¶éƒ½è¿½æ±‚çš„ä¸œè¥¿è£¹æŒŸ, æ¯”å¦‚GPA, å·¥èµ„ç­‰ç­‰ã€‚è¿™ä½å…„å¼Ÿæ’åˆ°äº†ç¬¬å››, æƒ³å¿…æ˜¯åšäº†ç›¸å½“å¤šçš„å·¥ä½œã€‚ 5. Yufei Guo (éƒ­å®‡é£) ä¸»é¡µ github google scholar åšå£«: 2015-2020, åŒ—å¤§ å­¦å£«: 2011-2015, åŒ—äº¬ç†å·¥ ä¸»è¦åšlosså’Œä¼˜åŒ–ç›¸å…³çš„, ä¹Ÿåšè¿‡ä¸€å®šçš„æ¨¡å‹(å°–å³°ç¥ç»ç½‘ç»œ)ã€‚è¿™ä½åŒå­¦22å¹´è¿˜æ‹¿åˆ°è¿‡å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘å§”çš„é¡¹ç›®, ä¹Ÿæœ‰å¯èƒ½æˆ‘ç†è§£æœ‰è¯¯, linkedInçš„ä¿¡æ¯ä¹Ÿéå¸¸æœ‰é™, è¿™å‘Šè¯‰æˆ‘ä»¬è¦ç§¯ææ›´æ–°linkedInç»™è‡ªå·±æ‰“å¹¿å‘Šå‘€ã€‚ 6. Li Jing google scholar ä¸»é¡µ linkedIn åšå£«: 2014-2019, MITçš„ç‰©ç†å­¦åšå£« å­¦å£«: 2010-2014, åŒ—å¤§ç‰©ç† IPhOé‡‘ç‰Œ, è¿™æ˜¯å›½å®¶é˜Ÿæ°´å‡†, å…¨å›½æ¯å¹´ä»…å››äºº åœ¨Metaåšåšå, éšååˆ°OpenAIå‚ä¸äº†Dalle3å’ŒSoraçš„å·¥ä½œã€‚æ–‡ç« å¼•ç”¨è¿˜æ˜¯æŒºå¤šçš„, æœ€æœ‰å½±å“åŠ›çš„å·¥ä½œæ˜¯å’ŒLeCunåˆä½œçš„Barlow twins: Self-supervised learning via redundancy reductionã€‚å› ä¸ºæ˜¯å­¦ç‰©ç†çš„, æ‰€ä»¥è¿˜ç”¨æ·±åº¦å­¦ä¹ æ¥è¿›è¡Œç²’å­æ¨¡æ‹Ÿå’Œé€†å‘è®¾è®¡, å‘è¡¨åœ¨äº†Science advancesä¸Šã€‚æˆ‘è§‰å¾—ä»–çš„ç‰©ç†åŠŸåº•å’Œæ•°å­¦åŠŸåº•éƒ½æ˜¯ååˆ†æ·±åšçš„, åœ¨Metaçš„å·¥ä½œä¹Ÿè·å¾—äº†æ¯”è¾ƒå¤§çš„å½±å“åŠ›, æœ€ååˆ°OpenAIä¹Ÿæ˜¯æ¸…ç†ä¹‹ä¸­çš„, ä½†æ˜¯æ— æ³•ä»è¿‡å»çš„å·¥ä½œä¸­çœ‹å‡ºä»–åœ¨Soraä¸­ä»äº‹çš„å·¥ä½œå’Œè´¡çŒ®ã€‚ 7. David Schnurr linkedIn ä¸»é¡µ å­¦å£«: 2008-2012, UCSB æ˜¯ä¸€ä¸ªå…¸å‹çš„å·¥ç¨‹å¸ˆ, åœ¨Graphiq, Uberåšå¯è§†åŒ–å¹³å°, ä¸»è¦æŠ€èƒ½æ˜¯JSå’ŒPython, OpenAIçš„Node.js APIå¼•æ“å°±æ˜¯ä»–å†™çš„ã€‚ 8. Joe Taylor linkedIn å­¦å£«: Academy of Art University çœ‹èµ·æ¥æ˜¯è®¾è®¡å­¦ä¸“ä¸šçš„, ä»äº‹è¿‡ç½‘é¡µè®¾è®¡ä»¥åŠå›¾åƒè®¾è®¡, å‰ç«¯è®¾è®¡å’Œå¼€å‘ã€‚ Working on early research. Helping accelerate research, build product intuition and direction, building 0 -&gt; 1 engineering systems. Announcement post; å…¶å®ä¸æ˜¯å¾ˆæ‡‚è¿™å¥è¯æ˜¯ä»€ä¹ˆæ„æ€, æˆ‘è§‰å¾—è¿˜æ˜¯ä»äº§å“, è®¾è®¡ä»¥åŠå®£ä¼ çš„è§’åº¦å»å‚ä¸å·¥ä½œã€‚ 9. Troy Luhman google scholar åšäº†éå¸¸å¤šdiffusion ç›¸å…³çš„å·¥ä½œ, ä¸»è¦å…³æ³¨é«˜æ•ˆç”Ÿæˆå’Œé¢†åŸŸç”Ÿæˆ, æ¯”è¾ƒæœ‰æ„æ€çš„æ˜¯æ–‡ç« åªæœ‰ä¸¤ä¸ªä½œè€…, åˆä½œè€…æ˜¯ä¸‹é¢çš„Eric Luhman, æˆ‘è§‰å¾—å¯èƒ½æ˜¯ä¸€å®¶äººã€‚ 10. Eric Luhman æ¨ç‰¹ ä¸»è¦å’ŒTroy Luhmanåˆä½œ, åšdiffusion é¢†åŸŸç›¸å…³çš„å·¥ä½œã€‚ 11. Clarence Ng å­¦å£«: åŠ æ‹¿å¤§æ»‘é“å¢å¤§å­¦, è®¡ç®—æœºä¸ç³»ç»Ÿè®¾è®¡ åœ¨AWS, google Cloud, Orach cloudéƒ½åšè¿‡ã€‚ å…¸å‹çš„å·¥ç¨‹å¸ˆ, ä¸»è¦åšäº‘, åˆ†å¸ƒå¼ç³»ç»Ÿå’Œæ€§èƒ½ä¼˜åŒ–, è¿˜åšè¿‡å¯¹è±¡å­˜å‚¨, å¯èƒ½å¯¹Soraçš„è§†é¢‘è¯»å–å’Œå¤„ç†è¿›è¡Œäº†ä¼˜åŒ–ã€‚å·¥ç¨‹ç»éªŒæå…¶ä¸°å¯Œ, åšçš„é¡¹ç›®ä¹Ÿå¾ˆå¤§, æ˜¯ä¸ªä¼˜ç§€çš„äººæ‰ã€‚ 12. Ricky Wang å­¦å£«: UCB, 2013-2016 ä¸»è¦ä¹Ÿæ˜¯å·¥ç¨‹å¸ˆçš„ç”»åƒ, åœ¨Instagramå’ŒMetaäº¤æ›¿å·¥ä½œäº†éå¸¸å¤šå¹´ã€‚ 13. Aditya Ramesh ä¸»é¡µ DBLP [summary]https://typeset.io/authors/aditya-ramesh-4xp87jcxw7 æ˜¯dalleå’Œdalle2çš„ä½œè€…, è¿˜å±‚å‚ä¸GPTçš„å·¥ä½œ, å­¦æœ¯åŠŸåº•æ·±åš, æœ‰14.5kçš„å¼•ç”¨, åœ¨OpenAIåº”è¯¥ä¹Ÿç®—æ¯”è¾ƒå…ƒè€çš„ä»»åŠ¡, æ‰€ä»¥æ˜¯é¡¹ç›®çš„æ€»è´Ÿè´£äººã€‚ä»è¿™ä¸ªè§†é¢‘çœ‹, æ–‡å­—ç¨¿, ä»–è¿˜æœ‰ç‚¹å‘†å‘†çš„ã€‚ æ€»ç»“æ€»soraçš„ä¸»è¦ä½œè€…çœ‹, æˆ‘ä»¬å¯ä»¥ä»Soraå›¢é˜Ÿå­¦ä¹ åˆ°çš„ç»éªŒæ˜¯: è¶…å‰çš„è®¤çŸ¥, æ³¨é‡scalable å¤§å‚çš„ç»å†å’Œå¤§å‚çš„èµ„æºçš„æ”¯æŒ, åšå‡ºå‡ºè‰²çš„å·¥ä½œ æå¼ºçš„å·¥ç¨‹èƒ½åŠ› è‰¯å¥½å¯æ‰©å±•çš„è®­ç»ƒç³»ç»Ÿåšæ”¯æ’‘ å¥½çš„æ•°å­¦åŠŸåº•å’Œç§‘ç ”ç»éªŒ å‚ä¸è¿‡å¤šç§é‡å¤§é¡¹ç›®çš„leaderçš„å­˜åœ¨ æˆ‘è§‰è¿™ä¸€åˆ‡è¿˜æ˜¯å€¼å¾—è‡ªå·±åæ€çš„, ç‰¹åˆ«æ˜¯å¤§å‚çš„ç»å†å’Œèµ„æºæ–¹é¢, æˆ‘è§‰å¾—è¿™æ˜¯å‡ ä¹æ‰€æœ‰äººçš„å…±åŒç‰¹å¾ã€‚å¸Œæœ›è¿™ç¯‡åšå®¢ä¸è¯¸å›å…±å‹‰, å…±åŒåŠªåŠ›å’Œè¿›æ­¥ã€‚","link":"/blog/Sora-authors/"},{"title":"Transformer-Performance","text":"transformer æ€§èƒ½åˆ†æç®€ä»‹éšç€æ¨¡å‹çš„ä¸æ–­å˜å¤§, æ¨¡å‹çš„æ¨ç†å’Œè®­ç»ƒæˆæœ¬åœ¨ä¸æ–­çš„æé«˜, å¦‚ä½•æ›´å¥½çš„ä¼˜åŒ–æ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„æ€§èƒ½æˆä¸ºéå¸¸é‡è¦çš„é¢†åŸŸ, 10%çš„æ€§èƒ½æå‡å¯èƒ½å¸¦æ¥æ•°åä¸‡ä¹ƒè‡³æ•°ç™¾ä¸‡æˆæœ¬çš„èŠ‚çœã€‚ ä¸»è¦çš„æ€§èƒ½ä¼˜åŒ–ä¸€èˆ¬æ¥è‡ªäºåœ¨è®¡ç®—é€»è¾‘ä¸å˜çš„æƒ…å†µä¸‹å¯¹ç¡¬ä»¶æ›´å¥½çš„ä¼˜åŒ–å’Œåˆ©ç”¨, æˆ–è€…åœ¨å°‘é‡æŸå¤±æ¨¡å‹è®¡ç®—ç²¾åº¦çš„æƒ…å†µä¸‹å‡å°‘æ¨¡å‹æ¨ç†çš„è®¡ç®—é‡å’Œæ”¾å­˜é‡, ä»è€Œæé«˜æ€§èƒ½ã€‚ è¿™ç¯‡åšå®¢ä¸»è¦å­¦ä¹ è¿™ç¯‡åšå®¢çš„åˆ†ææ€è·¯, å…ˆä»å†…å®¹çš„ç¿»è¯‘å’Œç†è§£å…¥æ‰‹, éšåå°†åšå®¢çš„å†…å®¹æ‰©å±•åˆ°diffusion transformerä»¥åŠè®­ç»ƒç›¸å…³çš„æ€§èƒ½åˆ†æ, ä»è€Œç»™å¦‚ä½•ä¼˜åŒ–ä»¥æ›´å¥½çš„ç†è®ºæŒ‡å¯¼ã€‚ çº¦å®šå’ŒåŸºç¡€åœ¨æœ¬åšå®¢ä¸­æˆ‘ä»¬å¯¹æ•°å€¼çš„çº¦å®šå’Œå‚è€ƒçš„åšå®¢æœ‰ä¸€å®šçš„å‡ºå…¥, å¯¹äºå†…å­˜å ç”¨, æˆ‘ä»¬åªè®¡ç®—å…ƒç´ çš„ä¸ªæ•°, ä¹Ÿå°±æ˜¯ä¸è€ƒè™‘æ¯ä¸ªå‚æ•°çš„ä½å®½, åªè®¡ç®—å‚æ•°çš„ä¸ªæ•°ã€‚é»˜è®¤æƒ…å†µä¸‹ çŸ©é˜µå‘é‡ä¹˜çš„è®¡ç®—é‡:å¯¹äºçŸ©é˜µå‘é‡ä¹˜ , çš„è®¡ç®—é‡ä¸º: ã€‚å¯¹äº ,çŸ©é˜µçŸ©é˜µä¹˜çš„è®¡ç®—é‡ä¸º , å…¶ä¸­ç³»æ•°2åˆ†åˆ«ä¸ºä¹˜å’ŒåŠ ã€‚ kv cacheè§£è¯»transformeråœ¨æ¨ç†æ—¶åˆ†ä¸¤ä¸ªé˜¶æ®µ, æ˜¯å¤„ç†ç»™å®šçš„prompt(æ˜¯ä¸€æ¬¡ç®€å•çš„forward, tokenä¸€èµ·å–‚å…¥æ¨¡å‹ä¸­) éšåæ˜¯ä¸æ–­è‡ªå›å½’åœ°äº§ç”Ÿåç»­çš„tokenåºåˆ—(æ¯æ¬¡åªäº§ç”Ÿä¸€ä¸ªtoken)ã€‚è¿™é‡Œéœ€è¦æä¸€ç‚¹çš„æ˜¯, transformerè§£ç æ—¶ä¹‹å‰æ‰€æœ‰è®¡ç®—çš„tokenå¯¹åº”çš„latentéƒ½å’Œåç»­çš„tokenæ²¡æœ‰å…³ç³»(å› ä¸ºattention maskçš„å­˜åœ¨, è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæ¨¡å‹æ˜¯autoregressive, è¯¦æƒ…è¯·è§)ã€‚ å› ä¸ºä¹‹å‰çš„tokenå’Œåé¢çš„tokenæ— å…³ç³», æ‰€ä»¥è¿™éƒ¨åˆ†çš„å€¼æ— éœ€é‡å¤è®¡ç®—, ä½†æ˜¯å†å²çš„Kå’ŒVåœ¨æ¯æ¬¡è®¡ç®—ä¸­éƒ½éœ€è¦(åªè¢«self attention éœ€è¦), æ‰€ä»¥éœ€è¦å°†æ¯ä¸ªtransformer blockçš„å†å²KVä¿å­˜èµ·æ¥, è¿™éƒ¨åˆ†ä¿å­˜çš„å†…å®¹è¢«ç§°ä¹‹ä¸ºKV cache, åœ¨ä½¿ç”¨KV cacheçš„æƒ…å†µä¸‹, transformeræ¯æ¬¡åªéœ€è¦è¾“å…¥ä¸€ä¸ªtokenç”¨ä»¥è®¡ç®—, æ— éœ€è¾“å…¥å†æ¬¡å‰é¢çš„å…¨éƒ¨åºåˆ—, è®¡ç®—é‡æ˜¯éšç€tokenä¸ªæ•°çº¿æ€§å¢é•¿ã€‚ å¯¹äºæ¯ä¸ªtoken, éœ€è¦ä¿å­˜çš„KV cacheå‚æ•°é‡ä¸º: å…¶ä¸­(1+1)è¡¨ç¤ºkå’Œvã€‚ å¯¹äºè®¡ç®—ä¸€ä¸ªæ–°çš„tokençš„KV cache, æˆ‘ä»¬éœ€è¦çš„è®¡ç®—é‡ä¸º: åŒæ—¶æˆ‘ä»¬éœ€è¦çš„è®¿å­˜é‡ä¸º: å–å‚æ•°è®¿å­˜é‡å–éšå±‚è®¿å­˜é‡ æ€»ä½“è€Œè¨€, æ˜¯å–å‚æ•°çš„æ”¾å­˜é‡å å¤§å¤´, tokençš„è®¿å­˜é‡å¯å¿½ç•¥ã€‚ å¯¹äºA100GPUè€Œè¨€, fp16çš„æ€§èƒ½ä¸º312TFlops, å†…å­˜å¸¦å®½ä¸º1.5T/s, åˆ™ç”¨äºè®¡ç®—ä¸€ä¸ªtokençš„KVè®¿å­˜è€—æ—¶å’Œè®¡ç®—è€—æ—¶ä¸º: å¯è§, ç”¨äºè®¿å­˜çš„æ—¶é—´æ˜¯ç”¨äºè®¡ç®—çš„208å€ä¹‹å¤š, è¿™è¯´æ˜transformerè§£ç çš„è¿‡ç¨‹æ˜¯å†…å­˜ç“¶é¢ˆ, å†…å­˜å¸¦å®½ã€‚é€ æˆè¿™ç§ç“¶é¢ˆçš„ä¸»è¦åŸå› æ˜¯è§£ç æ—¶åªè®¡ç®—ä¸€ä¸ªtoken, è®¡ç®—é‡å°, è€Œæ¨¡å‹çš„å‚æ•°å¾ˆå¤§ã€‚ éœ€è¦æ³¨æ„çš„æ˜¯, KVcacheçš„å­˜åœ¨å¹¶ä¸æ˜¯ä»…ä»…ä¸ºäº†èŠ‚çœè®¡ç®—KVæœ¬èº«æ‰€éœ€è¦çš„è®¡ç®—é‡, è€Œæ˜¯èŠ‚çœäº†å‰é¢æ‰€æœ‰tokené€šè¿‡æ¨¡å‹æ‰€éœ€è¦çš„è®¡ç®—é‡ã€‚å¦‚æœæ²¡æœ‰KVcache, transformerçš„è§£ç è¿‡ç¨‹ä¼šä¸ºå¹³æ–¹çº§å¢é•¿çš„è®¡ç®—é‡(ç¬¬ä¸€æ¬¡forward1ä¸ªtoken, ç¬¬äºŒæ¬¡forward2ä¸ªtoken, ç¬¬ä¸‰æ¬¡forward3tokenâ€¦.), è¿™å°†éš¾ä»¥æ‰¿å—ã€‚ ğŸ’¡ å¦‚æœæˆ‘ä»¬å¢å¤§batch size, èƒ½å¤Ÿè·å¾—åœ¨æ¯æ¬¡è§£ç æ—¶æ›´å¤šçš„è®¡ç®—é‡å’Œç›¸è¿‘çš„è®¿å­˜é‡(å› ä¸ºä¸»è¦æ”¾å­˜é‡åœ¨æ¨¡å‹æƒé‡), è€Œç”±äºè®¡ç®—éå¸¸ä¾¿å®œ, æˆ‘ä»¬çš„æ”¶ç›Šæ˜¯å¤§çš„(é¢å¤–èŠ±1%çš„æ—¶é—´, å¤šè·å¾—ä¸€ä¸ªtokençš„è§£ç ), è¿™å¯èƒ½ä¼šæé«˜æ¯ä¸ªtokençš„å»¶è¿Ÿ, ä½†æ˜¯èƒ½å¤Ÿæå¤§å¢åŠ æ¨¡å‹tokençš„ååã€‚å¯¹æ­¤å·²ç»æœ‰ç ”ç©¶(ORCA)è¿›è¡Œäº†ä¼˜åŒ–, ä½¿å¾—æ¨¡å‹ååä¸Šäº†ä¸€ä¸ªé‡çº§, é€ ç¦äº†äººç±»ã€‚ å®¹é‡è®¡ç®—æ¥ä¸‹æ¥è¿›è¡Œç®€å•çš„å®¹é‡è®¡ç®—åˆ†æ, å¯¹äºä¸€ä¸ª52B(52e9 numel)çš„æ¨¡å‹, å¦‚æœé‡‡ç”¨åŠç²¾åº¦å­˜å‚¨, åˆ™å¤§çº¦éœ€è¦104GB(104e9 Bytes, two bytes for each parameter)çš„ç©ºé—´, å•å¡æ— æ³•æ”¾ä¸‹, åŒæ—¶åœ¨æ¨ç†æ—¶KVcache ä¹Ÿéœ€è¦å ç”¨ç©ºé—´ã€‚ ç»™å®š4å¡çš„A100 40Gå¡, æˆ‘ä»¬å¯ä»¥ç®€å•è®¡ç®—å¯ä»¥sample çš„tokenæ•°é‡ã€‚å·²çŸ¥æ¨¡å‹å·²ç»å äº†104G, åªæœ‰16Gç•™ç»™äº†KVcacheã€‚æ¯ä¸ªtokenéœ€è¦çš„ç©ºé—´ä¸º: æ‰€ä»¥16Gå¤§çº¦å¯ä»¥å®¹ä¸‹8000tokenã€‚ æ¨¡å‹å¹¶è¡Œæˆ‘ä»¬ä¸€èˆ¬è®¨è®ºçš„æ¨¡å‹å¹¶è¡Œæ˜¯æŒ‡å¼ é‡å¹¶è¡Œ, ä¹Ÿå°±æ˜¯å°†æ¨¡å‹çºµå‘åˆ‡å¼€, æ¯å¼ å¡ä¸Šéƒ½æœ‰æ‰€æœ‰blockå‚æ•°çš„ä¸€éƒ¨åˆ†ã€‚æ¨¡å‹å¹¶è¡Œèƒ½å¤Ÿä½¿å¾—æ¯å¼ å¡åªæ‰¿å—ä¸€éƒ¨åˆ†çš„æ¨¡å‹å‚æ•°å­˜å‚¨å’Œæœ‰ä¸€éƒ¨åˆ†çš„è®¡ç®—é‡, è¿™äº›éƒ¨åˆ†æ”¶åˆ°å¡çš„æ•°é‡çš„å½±å“ã€‚æ¨¡å‹å¹¶è¡Œä¼šé¢å¤–å¸¦æ¥çš„å¼€é”€æ˜¯åˆ†å—è®¡ç®—ååŒæ­¥è®¡ç®—ç»“æœçš„é€šä¿¡å¼€é”€, è¿™éƒ¨åˆ†ä¼šå½±å“åˆ°æ¨ç†çš„å»¶è¿Ÿã€‚ æ­¤å¤–, å°†æ¨¡å‹æ¨ªå‘åˆ‡åˆ†, æ¯å¼ å¡åŒ…å«äº†è‹¥å¹²ä¸ªå®Œæ•´çš„block, è¿™æ ·çš„æ–¹æ³•è¢«ç§°ä¸ºæµæ°´çº¿å¹¶è¡Œ, ç”±äºæ¯ä¸ªtokenä¼šä¾æ¬¡é€šè¿‡æ‰€æœ‰blockä¹Ÿå°±ä¼šä¾æ¬¡é€šè¿‡æ¯å¼ å¡ä¸€æ¬¡, æ¯æ¬¡åªæœ‰ä¸€å¼ GPUåœ¨è¿›è¡Œè®¡ç®—, æ‰€ä»¥æ¯ä¸ªtokençš„å»¶è¿Ÿå’Œå•å¡åŸºæœ¬ä¸€è‡´, ä½†æ˜¯é€šè¿‡æµæ°´çº¿çš„æ–¹æ³•ä¸æ–­å–‚å…¥token, æ€»çš„ååå¯ä»¥è¾¾åˆ°å’Œ4å¼ å¡ä¸€è‡´ã€‚æµæ°´çº¿å¹¶è¡Œå”¯ä¸€çš„å¥½å¤„åœ¨äºéœ€è¦çš„é€šä¿¡é‡æ¯”è¾ƒå°, è¿™é€‚åˆå¡é—´å¸¦å®½æ¯”è¾ƒå°çš„åœºæ™¯ã€‚æµæ°´çº¿å¹¶è¡Œéœ€è¦åœ¨æ¯å¼ å¡ä¹‹é—´ä¼ é€’latent, è€Œå¼ é‡å¹¶è¡Œéœ€è¦æ¯ä¸ªblockä¹‹é—´è¿›è¡Œæ¯å¼ å¡ä¹‹é—´çš„é€šä¿¡, é€šä¿¡é‡ä¸Šä¸€ä¸ªé‡çº§ã€‚ çŸ©é˜µå‘é‡ä¹˜åˆ†å—å¹¶è¡Œè€ƒè™‘æƒé‡çŸ©é˜µ, GPUæ•°é‡ä¸ºN, è¾“å…¥å‘é‡å¤§å°ã€‚åˆ™è¾“å‡ºå¤§å°åº”å½“ä¸ºã€‚ åˆ†å—å, æ¯ä¸ªGPUçš„æƒé‡çŸ©é˜µå¤§å°ä¸º, è¾“å…¥åŒæ—¶ä¹Ÿè¢«åˆ‡åˆ†è¢«å‘é‡å¤§å° ã€‚æ¯ä¸ªGPUåˆ†åˆ«åˆ†é…åˆ°çš„çŸ©é˜µå‘é‡ä¹˜, å¾—åˆ°çš„è¾“å‡ºå¤§å°ä¸ºã€‚æ¯ä¸ªå¾—åˆ°çš„æ­¤æ—¶æˆ‘ä»¬å¯ä»¥çŸ¥é“è™½ç„¶æ¯ä¸ªGPUå¾—åˆ°çš„ç»“æœå’Œè¾“å‡ºå¤§å°ä¸€è‡´, ä½†æ˜¯å¯çŸ¥çœŸæ­£çš„ç»“æœæ˜¯æ¯ä¸ªGPUè®¡ç®—å¾—åˆ°çš„ç»“æœåšæ±‚å’Œå¾—åˆ°çš„, è¿™å°±éœ€è¦åšä¸€æ¬¡All reduceçš„æ“ä½œ, æ˜¯çš„æ¯ä¸ªGPUä¸Šéƒ½æ˜¯æ­£ç¡®çš„ç»“æœä¹‹å, å†è¿›è¡Œåˆ‡åˆ†, è¿›è¡Œåç»­çš„åˆ†å—å¹¶è¡Œè®¡ç®—ã€‚ attentionçš„å¹¶è¡ŒAttentionçš„å¹¶è¡Œæ˜¯é€šè¿‡åœ¨attention headçš„å±‚é¢è¿›è¡Œå¹¶è¡Œã€‚headçš„åˆ‡åˆ†ç»´åº¦åˆšå¥½æ˜¯åœ¨ ä¸­çš„n, æ‰€ä»¥ä¹‹å‰çš„è®¡ç®—ç»“æŸå, æ— éœ€é¢å¤–çš„é€šä¿¡å°±å¯ä»¥ç›´æ¥è¿›è¡Œattentionè®¡ç®—(å‰ææ˜¯num headæ˜¯å¡æ•°çš„nå€)ã€‚è®¡ç®—ç»“æŸå, ç”šè‡³å¯ä»¥é€šè¿‡ä¹‹åå†è¿›è¡Œé€šè®¯åˆå¹¶ã€‚åŒç†, KVcacheä¹Ÿæ˜¯åœ¨headè¿™ä¸ªç»´åº¦ä¸Šå­˜å‚¨åœ¨ä¸åŒçš„GPUä¸Šã€‚ å„ä¸ªæ¨¡å—è®¡ç®—é‡å’Œè®¿å­˜é‡åˆ†ææ ‡è®°:åœ¨diffusion transformerä¸­, num_tokens = s = T * H * W MLP mlpçš„å‚æ•°ä¸º in_d , mid_d, out_d ã€‚é€šå¸¸æƒ…å†µè€Œè¨€, in_d = out_d, mid_d = 4 * in_d Flops = è®¿å­˜é‡: è¿™é‡Œçš„è®¿å­˜é‡åŒ…æ‹¬æŠŠç»“æœå†™åˆ°å†…å­˜ä¸­ã€‚ Vanilla self attention attentionå‚æ•°ä¸º: in_d, mid_d , out_d ã€‚é€šå¸¸æƒ…å†µè€Œè¨€, ä¸‰è€…ç›¸ç­‰ã€‚ Flops = è®¿å­˜é‡: Vanilla cross attention å‚æ•°ä¸º: in_d, context_d, mid_d, out_d, é€šå¸¸åªæœ‰context_d å’Œå…¶ä»–ä¸‰è€…ä¸åŒ Flops = è®¿å­˜é‡: Spatial self attention attentionå‚æ•°ä¸º: in_d, mid_d , out_d ã€‚é€šå¸¸æƒ…å†µè€Œè¨€, ä¸‰è€…ç›¸ç­‰ã€‚ Flops = è®¿å­˜é‡: Spatial cross attention å‚æ•°ä¸º: in_d, context_d, mid_d, out_d, é€šå¸¸åªæœ‰context_d å’Œå…¶ä»–ä¸‰è€…ä¸åŒ Flops = è®¿å­˜é‡: è®¡ç®—é‡å’Œvanillaä¸€è‡´ temprol self attention attentionå‚æ•°ä¸º: in_d, mid_d , out_d ã€‚é€šå¸¸æƒ…å†µè€Œè¨€, ä¸‰è€…ç›¸ç­‰ã€‚ Flops = è®¿å­˜é‡: å°è®¨è®ºå¯çŸ¥MLPçš„è®¡ç®—é‡éšç€åºåˆ—é•¿åº¦çº¿æ€§å¢é•¿, è€Œsefl-Attentionçš„è®¡ç®—é‡æ˜¯å¹³æ–¹çº§å¢é•¿, åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥è®¡ç®—ä¸€ä¸‹ç»å…¸åœºæ™¯ä¸‹, å½“åºåˆ—é•¿åº¦åˆ°è¾¾ä»€ä¹ˆæ°´å¹³æ—¶, Attentionçš„è®¡ç®—é‡ä¼šæˆä¸ºä¸»è¦éƒ¨åˆ†ã€‚ in_d = mid_d = out_d, MLP mid_d=4in_d åˆ™MLPçš„è®¡ç®—é‡å…¬å¼ä¸º: Attentionè®¡ç®—é‡å…¬å¼ä¸º: åœ¨dim = 1536çš„æƒ…å†µä¸‹è®¡ç®—, ç”»å›¾å¦‚ä¸‹: åœ¨å¤§çº¦3Kä»¥å, Attentionçš„è®¡ç®—æˆä¸ºä¸»è¦éƒ¨åˆ†ã€‚ backwardåˆ†æè€ƒè™‘ä»¥ä¸‹çš„ä¸‰å±‚MLP, xä¸ºè¾“å…¥, ä¸ºä¸‰ä¸ªæƒé‡çŸ©é˜µ, ä¸ºä¸‰ä¸ªæ¿€æ´», æœ€åå’Œground truthè®¡ç®—å¾—åˆ°lossã€‚ remark:è®¡ç®—è¾“å…¥çš„ç»´åº¦å¤§å†™ä¸ºæƒé‡çŸ©é˜µå°å†™ä¸ºä¸­é—´æ¿€æ´» Operation Computation mul shape FLOP forward Computation FLOP backward mul shape Input ReLU Derivative Hidden1 ReLU Derivative Hidden2 ReLU Loss Update æ³¨æ„åˆ°, å› ä¸ºinput x æ— éœ€è®¡ç®—æ¢¯åº¦, æ‰€ä»¥å¯¹äºç¬¬ä¸€å±‚è€Œè¨€, backwardèŠ‚çœäº†çº¦ä¸€åŠçš„è®¡ç®—é‡ã€‚æ‰€ä»¥åœ¨ç½‘ç»œè¾ƒæ·±çš„æƒ…å†µä¸‹, backwardçš„è®¡ç®—æ—¶é—´çº¦ä¸ºforwardè®¡ç®—æ—¶é—´çš„ä¸¤å€ã€‚ å‚è€ƒèµ„æ–™ https://kipp.ly/transformer-inference-arithmetic/ https://www.alignmentforum.org/posts/fnjKpBoWJXcSDwhZk/what-s-the-backward-forward-flop-ratio-for-neural-networks","link":"/blog/Transformer-Performance/"},{"title":"sequence parallel","text":"å‰è¨€éšç€Soraå’Œkimiçš„å¤§ç«, è§†é¢‘æ¨¡å‹å’Œè¶…é•¿åºåˆ—è¯­è¨€æ¨¡å‹çš„å®è·µä¸æ–­è¢«äººä»¬æ‘†åˆ°æ›´é‡è¦çš„ä½ç½®, è¿™ç¯‡åšå®¢ä¸»è¦ä»éœ€æ±‚å’ŒåŸºæœ¬æ€è·¯ä»¥åŠå®è·µè¿™å‡ ä¸ªæ–¹é¢æ¥è®²è§£ä¸€ä¸‹åºåˆ—å¹¶è¡Œç›¸å…³çš„å†…å®¹ã€‚ éœ€æ±‚ä»äº§å“éœ€æ±‚çš„è§’åº¦çœ‹, é•¿åºåˆ—æ˜¯å¿…ç„¶çš„éœ€æ±‚ã€‚ä»è¯­è¨€æ¨¡å‹çœ‹, åšè¶…é•¿æ–‡æœ¬æ£€ç´¢ä»¥åŠæ‘˜è¦æœ‰ç¡®å®šçš„éœ€æ±‚(ä¾‹å¦‚å¹³æ—¶çœ‹æ–‡çŒ®)ã€‚soraèƒ½å¤Ÿç”Ÿæˆè¶…é•¿è§†é¢‘, åœ¨ä½¿ç”¨vanilla attentionçš„æƒ…å†µä¸‹, attentionçš„åºåˆ—é•¿åº¦å°†ä¸º(T, H, W), ä¹Ÿå°±æ˜¯æ—¶é•¿, é«˜åº¦, å®½åº¦ä¸‰è€…çš„ä¹˜ç§¯å¢é•¿, åºåˆ—é•¿åº¦æ¯”å›¾åƒæ¨¡å‹ä¸Šä¸€ä¸ªé‡çº§, è¿™ä¹Ÿä¸€å®šä¼šæˆä¸ºsoraè®­ç»ƒå’Œæ¨ç†çš„éš¾é¢˜ã€‚å°½ç®¡å½“å‰çš„flash attentionçš„æ˜¾å­˜æ¶ˆè€—èƒ½å¤Ÿè¢«ä¼˜åŒ–åˆ°çº¿æ€§å¢é•¿çš„ç¨‹åº¦, ä½†æ˜¯å½“åºåˆ—é•¿åº¦è¶³å¤Ÿé•¿, æ˜¾å­˜ä¾ç„¶å¯èƒ½ä¸å¤Ÿã€‚ å°±æ­¤, æˆ‘ä»¬çš„é—®é¢˜è¢«å®šä¹‰ä¸º: å¦‚ä½•è®©transformeræ”¯æŒè¶…é•¿åºåˆ—çš„è®­ç»ƒå’Œæ¨ç† é—®é¢˜çš„æ ¸å¿ƒ: æ¥æºäºæ˜¾å­˜è£…ä¸ä¸‹è¶…é•¿åºåˆ—å¸¦æ¥çš„æ˜¾å­˜éœ€æ±‚, è€Œéæ¨¡å‹å¤ªå¤§å¸¦æ¥çš„æ˜¾å­˜æº¢å‡º å¯èƒ½æ–¹æ³•: ä¼˜åŒ–æ˜¾å­˜æˆ–è€…ä½¿ç”¨å¤šGPUå¹¶è¡Œè®¡ç®—åˆ†æ‘Šæ˜¾å­˜å’Œè®¡ç®— åŸºæœ¬æ€è·¯é¦–å…ˆæˆ‘ä»¬éœ€è¦å°†ä¸€å¥è¯é“­è®°äºå¿ƒ, é»˜å¿µä¸‰é: transformeræ¨¡å‹ä¸­, åºåˆ—çš„æ¦‚å¿µä»…åœ¨attentionè¿™ä¸ªæ“ä½œä¸­è¢«éœ€è¦, åœ¨åšMLPç­‰å…¶ä»–æ“ä½œæ—¶, æ‰“ä¹±åºåˆ—ç”šè‡³æ‰“ä¹±batchéƒ½æ˜¯å¯ä»¥çš„, åªè¦åœ¨attentionæ“ä½œæ—¶å°†åºåˆ—é¡ºåºæ¢å¤å³å¯ã€‚ å¯¹äºè¶…é•¿åºåˆ—æ”¯æŒé—®é¢˜, å¯èƒ½æœ€ç›´æ¥çš„æƒ³æ³•å°±æ˜¯ä½¿ç”¨å¼ é‡å¹¶è¡Œ, å°†æ¨¡å‹åˆ‡åˆ†, å¯¹åº”çš„åºåˆ—ä¹Ÿåœ¨(B, L, D)çš„Dç»´åº¦è¢«åˆ‡åˆ†, ä»è€Œå¯ä»¥èŠ‚çœæ˜¾å­˜ã€‚ ä½†æ˜¯éœ€è¦æ³¨æ„çš„æ˜¯, æˆ‘ä»¬é‡åˆ°çš„é—®é¢˜æ˜¯æ¥è‡ªäºåºåˆ—è¿‡é•¿, è€Œæ¨¡å‹å¹¶éè¿‡å¤§, ç‰¹åˆ«æ˜¯diffusionçš„æ¨¡å‹éƒ½è¿˜éå¸¸å°, ä¸€å¼ æ˜¾å¡æ”¾çš„ä¸‹ã€‚å…¶æ¬¡, ä½¿ç”¨æ¨¡å‹å¹¶è¡Œä¸­é€”è®¡ç®—éœ€è¦çš„é€šä¿¡åŒæ­¥å¼€é”€è¾ƒå¤§, å°æ¨¡å‹åšå¼ é‡å¹¶è¡Œä¸å€¼å¾—ã€‚ å†æ¬¡å›æƒ³æˆ‘ä»¬é“­è®°äºå¿ƒçš„è¯, æˆ‘ä»¬å¯ä»¥æ€è€ƒ, å¯å¦å°†åºåˆ—(B, L, D) åœ¨Lç»´åº¦åˆ‡åˆ†, åœ¨å¤šå¼ å¡ä¸ŠåšMLPç­‰å’Œåºåˆ—æ— å…³çš„æ“ä½œ(æ— éœ€é€šä¿¡), åœ¨åšattentionæ—¶å°†ç›¸å…³çš„å†…å®¹ä»å…¶ä»–GPUè·å–, å†è¿›è¡Œattentionæ“ä½œ, å†å°†è®¡ç®—ç»“æœåŒæ­¥åˆ°å…¶ä»–GPUä¸Šã€‚è¿™æ ·æ¯”å¼ é‡å¹¶è¡Œçš„å¥½å¤„åœ¨äºæ— éœ€åˆ‡åˆ†æ¨¡å‹, å‡å°‘é€šä¿¡é‡, æé«˜æ¨¡å‹çš„ååä¸æ€§èƒ½ã€‚ åŸºæœ¬å®ç°æ¥ä¸‹æ¥ä»‹ç»å‡ ä¸ªå®ç°äº†åºåˆ—å¹¶è¡Œçš„åº“æˆ–è€…ç®—æ³•: çº¦å®š B: batch size L: seq len D: hidden dim A: attention head size Z: number of attention heads N: number of GPU Z x A = D Nä¸ªGPUä¸Šå­˜å‚¨äº†(B, L/N, D)çš„åºåˆ—, ç»™å‡ºåœ¨åˆ†å¸ƒå¼æƒ…å†µä¸‹è®¡ç®—self attentionçš„ç®—æ³•ã€‚ Ring self attention(RSA)è¿™æ ·çš„æ–¹å¼æ˜¯é€šè¿‡åœ¨queryçš„Lç»´åº¦ä¸Šåˆ‡åˆ†è¿›è¡Œåˆ†å¸ƒå¼çš„attentionçš„è®¡ç®—ã€‚é€šä¿¡çš„æ–¹å¼æ˜¯é€šè¿‡è¿›ç¨‹ä¹‹é—´æ¢è£…ä¼ é€’Kå’ŒVçš„åˆ†å—ç„¶åå¾—åˆ°æœ€åçš„è®¡ç®—ç»“æœ, è¿™æ ·çš„ç®—æ³•ä¸å—åˆ°Zå¤§å°çš„é™åˆ¶, å¯¹GPUçš„æ•°é‡æ˜¯å¯æ‰©å±•çš„ã€‚ ç¬¬ä¸€é˜¶æ®µ-ç¯çŠ¶ä¼ é€’åˆ†å—çš„Kæ¥å¾—åˆ°attention map ç¬¬äºŒé˜¶æ®µ-ç¯çŠ¶ä¼ é€’åˆ†å—çš„Vå¾—åˆ°æœ€åçš„ç»“æœ é€šä¿—çš„ç†è§£ring attentionçš„æœºåˆ¶, å…¶æ ¸å¿ƒçš„å¹¶è¡Œçš„ç‚¹åœ¨äº, attentionçš„è®¡ç®—æ˜¯å¯ä»¥åœ¨queryçš„sequence lensçš„ç»´åº¦ä¸Šåˆ†å—çš„, ä¹Ÿå°±æ˜¯ä¸€éƒ¨åˆ†çš„queryå’Œå®Œæ•´çš„keyå’Œvalueå°±å¯ä»¥å¾—å‡ºæ­¤éƒ¨åˆ†qeuryå¯¹åº”çš„è®¡ç®—ç»“æœã€‚è€Œç”±äºåºåˆ—è¿‡é•¿, keyå’Œvalueä¹Ÿè¢«æ‰“æ•£åœ¨ä¸åŒè¿›ç¨‹ä¸­, æ‰€ä»¥éœ€è¦ä»å…¶ä»–è¿›ç¨‹ä¸æ–­ä¼ é€’å¹¶è®¡ç®—ä»è€Œå¾—åˆ°å®Œæ•´çš„keyå’Œvalueä»¥å¾—åˆ°æœ€ç»ˆç»“æœã€‚ ä¸æ–­é›†é½keyå’Œvalueè¿™æ ·çš„è¿‡ç¨‹, æœ€ç®€å•çš„æ–¹å¼å°±æ˜¯é€šè¿‡è¿›ç¨‹é¡ºåºç‚¹åˆ°ç‚¹çš„æ–¹å¼å®Œæˆ, æ˜¾ç„¶è¿™æ ·çš„æ•ˆç‡æ˜¯ä¸å¤Ÿé«˜çš„, åœ¨ä¼ é€’è¿‡ç¨‹ä¸­å¦‚ä½•å°½é‡æŠŠå„ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„å¸¦å®½åˆ©ç”¨å¥½, åŒæ—¶åšå¥½è®¡ç®—å’Œé€šä¿¡çš„é‡å , è€Œringçš„æ–¹å¼å°±æ˜¯ç³»ç»Ÿé¢†åŸŸå…¸å‹çš„ç®—æ³•å’Œæ–¹å¼, èƒ½å¤Ÿåšåˆ°è¾ƒå¥½çš„åˆ©ç”¨å¸¦å®½, åœ¨æœ‰è‰¯å¥½çš„å®çº¿çš„æƒ…å†µä¸‹, å¯ä»¥åšåˆ°è®¡ç®—å’Œé€šä¿¡çš„é‡å ã€‚ Deepspeed ulyssAttentionçš„å¦å¤–ä¸€ç§å¹¶è¡Œæ–¹å¼å°±æ˜¯ç±»ä¼¼äºå¼ é‡å¹¶è¡Œçš„æŒ‰ç…§Attention headè¿›è¡Œåˆ‡åˆ†ã€‚ä¹Ÿå°±æ˜¯æ¯ä¸ªè¿›ç¨‹æ‹¥æœ‰å®Œæ•´çš„åºåˆ—é•¿åº¦, ä½†æ˜¯åªæœ‰ä¸€éƒ¨åˆ†çš„headä¸ªæ•°, è¿™æ ·åŒæ ·èƒ½å¤ŸèŠ‚çœæ˜¾å­˜, è€Œä¸”è¿™æ ·çš„æ–¹æ³•å¯ä»¥åšåˆ°ä¸æ”¹å˜Attentionçš„å®ç°, ä¹Ÿå°±æ˜¯ä»»ä½•çš„attentionç®—æ³•éƒ½å’ŒDeepspeed ulysså…¼å®¹ã€‚ä½†æ˜¯ç¼ºç‚¹æ˜¯å¹¶è¡Œçš„å¡çš„æ•°é‡ä¸è¶…è¿‡å¤´çš„ä¸ªæ•°Zã€‚ åºåˆ—å¹¶è¡Œè¦æ±‚åœ¨MLPå±‚æ— é¢å¤–çš„æ“ä½œ, æ‰€ä»¥æ¯ä¸ªè¿›ç¨‹ä¸­åº”è¯¥æœ‰éƒ¨åˆ†çš„åºåˆ—, ä½†æ˜¯åŒ…å«å®Œæ•´çš„attention head, åœ¨è¿›è¡Œattentionå¹¶è¡Œæ—¶, åˆè¦æ±‚æ¯ä¸ªè¿›ç¨‹éœ€è¦å®Œæ•´çš„åºåˆ—ä¸”æ˜¯éƒ¨åˆ†çš„å¤´ã€‚æ‰€ä»¥å¯ä»¥é‡è§çš„æ˜¯åœ¨è¿›è¡Œattentionæ“ä½œå‰, é€šè¿‡é€šä¿¡ç®—å­ä½¿å¾—æ¯ä¸ªè¿›ç¨‹æ‹¥æœ‰(B, L/N, ZxA) è½¬åŒ–åˆ°æ¯ä¸ªè¿›ç¨‹æ‹¥æœ‰(B, L, ZxA/N)çš„åºåˆ—å†…å®¹ã€‚attention æ“ä½œç»“æŸå, å†é€šè¿‡é€šä¿¡ç®—å­ä½¿å¾—æ¯ä¸ªè¿›ç¨‹ä»æ‹¥æœ‰(B, L, ZxA/N)çš„åºåˆ—å†…å®¹è½¬åŒ–ä¸º(B, L/N, ZXA)çš„åºåˆ—å†…å®¹ã€‚è¯¾ä»¶ä»…éœ€è¦æ“ä½œå¼€å§‹å‰, ç»“æŸåéœ€è¦è¿›è¡Œé€šä¿¡, attentionçš„ç®—å­æ˜¯å®Œå…¨ç‹¬ç«‹çš„, æ‰€ä»¥å¯ä»¥é‡‡ç”¨ä»»æ„attentionç®—å­çš„å®ç°ã€‚ Deepspeed ulyssçš„å®ç°ä¹Ÿéå¸¸ç®€æ´, é€šè¿‡æºä»£ç å°±å¯ä»¥çœ‹åˆ°: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102# https://github.com/microsoft/DeepSpeed/blob/master/deepspeed/sequence/layer.pyimport torchfrom typing import Any, Tuplefrom torch import Tensorfrom torch.nn import Moduleimport deepspeed.comm as distdef single_all_to_all(input, scatter_idx, gather_idx, group): seq_world_size = dist.get_world_size(group) inp_shape = list(input.shape) inp_shape[scatter_idx] = inp_shape[scatter_idx] // seq_world_size if scatter_idx &lt; 2: input_t = input.reshape( [seq_world_size, inp_shape[scatter_idx]] + \\ inp_shape[scatter_idx + 1:] ).contiguous() else: # transpose groups of heads with the seq-len parallel dimension, so that we can scatter them! input_t = input.reshape( [-1, seq_world_size, inp_shape[scatter_idx]] + \\ inp_shape[scatter_idx + 1:] ).transpose(0, 1).contiguous() output = torch.empty_like(input_t) dist.all_to_all_single(output, input_t, group=group) # if scattering the seq-dim, transpose the heads back to the original dimension if scatter_idx &lt; 2: output = output.transpose(0, 1).contiguous() return output.reshape( inp_shape[: gather_idx] + \\ [inp_shape[gather_idx] * seq_world_size,] + \\ inp_shape[gather_idx + 1:]).contiguous()class _SeqAllToAll(torch.autograd.Function): @staticmethod def forward(ctx: Any, group: dist.ProcessGroup, input: Tensor, scatter_idx: int, gather_idx: int) -&gt; Tensor: ctx.group = group ctx.scatter_idx = scatter_idx ctx.gather_idx = gather_idx return single_all_to_all(input, scatter_idx, gather_idx, group) @staticmethod def backward(ctx: Any, *grad_output: Tensor) -&gt; Tuple[None, Tensor, None, None]: return (None, _SeqAllToAll.apply(ctx.group, *grad_output, ctx.gather_idx, ctx.scatter_idx), None, None)class DistributedAttention(torch.nn.Module): \"\"\"Initialization. Arguments: local_attention (Module): local attention with q,k,v sequence_process_group (ProcessGroup): sequence parallel process group scatter_idx (int): scatter_idx for all2all comm gather_idx (int): gather_idx for all2all comm \"\"\" def __init__( self, local_attention: Module, sequence_process_group: dist.ProcessGroup, scatter_idx: int = 2, gather_idx: int = 0, ) -&gt; None: super(DistributedAttention, self).__init__() self.local_attn = local_attention self.spg = sequence_process_group self.scatter_idx = scatter_idx self.gather_idx = gather_idx def forward(self, query: Tensor, key: Tensor, value: Tensor, *args: Any) -&gt; Tensor: \"\"\" forward Arguments: query (Tensor): query input to the layer key (Tensor): key input to the layer value (Tensor): value input to the layer args: other args Returns: * output (Tensor): context output \"\"\" # TODO Merge three alltoall calls into one # TODO (Reza): change the api on the megatron-deepspeed side so that we only receive all data (q,k, and v) together! #in shape : e.g., [s/p:h:] query_layer = _SeqAllToAll.apply(self.spg, query, self.scatter_idx, self.gather_idx) key_layer = _SeqAllToAll.apply(self.spg, key, self.scatter_idx, self.gather_idx) value_layer = _SeqAllToAll.apply(self.spg, value, self.scatter_idx, self.gather_idx) #out shape : e.g., [s:h/p:] context_layer = self.local_attn(query_layer, key_layer, value_layer, *args) output = _SeqAllToAll.apply(self.spg, context_layer, self.gather_idx, self.scatter_idx) #out e.g., [s/p::h] return output æ ¸å¿ƒå®ç°å°±æ˜¯_SeqAllToAllè¿™ä¸ªå‡½æ•°çš„å®ç°, ç»™å®šgroup, åœ¨forwardçš„æ—¶å€™é€šè¿‡é€šä¿¡å°†å½“å‰è¿›ç¨‹éœ€è¦çš„åºåˆ—èšç§¯åˆ°å½“å‰è¿›ç¨‹, åœ¨backwardæ—¶, æˆ‘ä»¬é€šè¿‡åå±‚æ”¶åˆ°çš„æ¢¯åº¦ä¹Ÿåº”è¯¥é€šè¿‡é€šä¿¡åˆ†å‘åˆ°æ­£ç¡®çš„è¿›ç¨‹ä¸­, å¹¶ä»åˆ«çš„è¿›ç¨‹ä¸­å–åˆ°å±äºè‡ªå·±è¿›ç¨‹å†…å®¹çš„æ¢¯åº¦ã€‚ä»¥q, k, vçš„é€šä¿¡ç®—å­ä¸¾ä¾‹: forwardæ—¶, è¿›ç¨‹æ‹¥æœ‰(B, L/N, ZxA) çš„åºåˆ—å†…å®¹, é€šä¿¡åè¿›ç¨‹æ‹¥æœ‰(B, L, ZxA/N) backwardæ—¶, è¿›ç¨‹æ”¶åˆ°çš„æ¢¯åº¦æ˜¯(B, L, ZxA/N)å†…å®¹çš„æ¢¯åº¦, ä½†æ˜¯æœ¬è¿›ç¨‹éœ€è¦æ­£ç¡®å›ä¼ çš„æ¢¯åº¦æ˜¯(B, L/N, ZxA) åºåˆ—çš„æ¢¯åº¦, æ‰€ä»¥é€šè¿‡åŒæ ·çš„ç®—æ³•å¾—åˆ°æ­£ç¡®çš„æ¢¯åº¦ å¯¹äºé€šä¿¡çš„ç®—å­, æœ€ç®€å•çš„ç®—å­å°±æ˜¯AlltoAll, ä½¿å¾—æ¯ä¸ªè¿›ç¨‹åœ¨æŸä¸ªç¬é—´æ‹¥æœ‰(B, L, ZxA)çš„åºåˆ—, ç„¶åä¸¢å¼ƒä¸éœ€è¦çš„éƒ¨åˆ†è¿›è¡Œè®¡ç®—, æ˜¾ç„¶è¿™æ ·çš„æ–¹å¼ä¼šå‡ºç°ä¸å¿…è¦çš„æ˜¾å­˜åˆ†é…, æ²¡æœ‰åšåˆ°è¶³å¤Ÿä¼˜é›…çš„èŠ‚çœæ˜¾å­˜é—®é¢˜, æ‰€ä»¥deepspeedä½¿ç”¨çš„äº‹AlltoAll_singleè¿™æ ·çš„é€šä¿¡ç®—å­, å¯ä»¥ç†è§£ä¸ºå°†å¼ é‡å†…å®¹åœ¨è¿›ç¨‹é—´çš„æŸä¸¤ä¸ªç»´åº¦è¿›è¡Œè½¬ç½®, é€šä¿¡è¿‡ç¨‹æ— éœ€åˆ†é…å¾ˆå¤šå†…å®¹, è¿›ä¸€æ­¥æé«˜æ•ˆç‡ã€‚ä¸ºäº†å¤§å®¶å¯¹AlltoAll_singleæœ‰æ›´å¥½çš„ç†è§£, è¿™é‡Œé™„ä¸Špytorchå¯¹åº”ç®—å­çš„æ–‡æ¡£: torch.distributed.all_to_all_single(output, input, output_split_sizes=None, input_split_sizes=None, group=None, async_op=False) 12345678910111213&gt;&gt;&gt; input = torch.arange(4) + rank * 4&gt;&gt;&gt; inputtensor([0, 1, 2, 3]) # Rank 0tensor([4, 5, 6, 7]) # Rank 1tensor([8, 9, 10, 11]) # Rank 2tensor([12, 13, 14, 15]) # Rank 3&gt;&gt;&gt; output = torch.empty([4], dtype=torch.int64)&gt;&gt;&gt; dist.all_to_all_single(output, input)&gt;&gt;&gt; outputtensor([0, 4, 8, 12]) # Rank 0tensor([1, 5, 9, 13]) # Rank 1tensor([2, 6, 10, 14]) # Rank 2tensor([3, 7, 11, 15]) # Rank 3 æ€»ç»“æœ¬æ–‡ä»‹ç»äº†åºåˆ—å¹¶è¡Œè§£å†³çš„é—®é¢˜, ä»¥åŠä¸¤ç§ä¸»æµçš„å®ç°åºåˆ—å¹¶è¡Œçš„æ–¹å¼ã€‚å…¶å®ä¸¤ç§åºåˆ—å¹¶è¡Œå¯ä»¥æ··åˆä½¿ç”¨, ä»è€Œè¾¾åˆ°æ›´å¥½çš„å¹¶è¡Œåº¦å’Œæ€§èƒ½ã€‚åŒæ—¶åœ¨è¯­è¨€æ¨¡å‹ä¸­, å¸¦causal maskçš„æƒ…å†µä¸‹, ç®€å•çš„åºåˆ—åˆ‡åˆ†ä¼šå¯¼è‡´è¿›ç¨‹é—´è®¡ç®—è´Ÿè½½ä¸å‡è¡¡, éšåè¡ç”Ÿå‡ºstriped attentionã€‚","link":"/blog/sequence-parallel/"},{"title":"åŠ æ‹¿å¤§ç­¾è¯è®°","text":"å’Œå­¦å§åˆä½œä¸­äº†nipsï¼Œè¦å»åŠ æ‹¿å¤§ï¼Œæ‰€ä»¥å‡†å¤‡ç”³è¯·åŠ æ‹¿å¤§ç­¾è¯ã€‚ ç„¶åå› ä¸ºæ„å¤§åˆ©ç­¾è¯å¤±åˆ©ï¼Œç„¶ååŠ æ‹¿å¤§ç­¾è¯å°±æŠ±ç€æ‘†çƒ‚çš„å¿ƒæ€ï¼Œéšä¾¿å¡«ï¼Œç­¾è¯typeé€‰othersï¼Œç„¶åèµ„é‡‘è¯æ˜ä¹Ÿä¸ç®¡äº†éšä¾¿æ‰“ä¸ªæµæ°´å°±ä¸Šï¼Œä¸»æ‰“çš„å°±æ˜¯ä¸€ä¸ªçˆ±è¿‡ä¸è¿‡ã€‚å› ä¸ºç»„é‡Œå¾ˆå¤šäººéƒ½è¢«checkäº†ï¼Œè‡ªå·±å¿ƒæ€è‰¯å¥½ã€‚ ç»“æœè«åå…¶å¦™å°±è¿‡äº†ï¼Œè¿™å¯èƒ½å°±æ˜¯æ— å¿ƒæ’æŸ³æŸ³æˆè«å§ï¼ˆdogeï¼‰ã€‚ å…¶å®èº«è¾¹ä¸»è¦è¢«checkçš„ç‚¹å°±æ˜¯æ»¡è¶³äº†é‡è¦é«˜æ ¡ã€åšå£«ã€è®¡ç®—æœºç­‰å‡ ä¸ªæ ‡ç­¾ï¼Œå°±å¾ˆæœ‰å¯èƒ½checkï¼Œæ‰€ä»¥å»ºè®®æœ¬ç§‘é˜¶æ®µå°±å‘æ–‡ç« åŠç­¾è¯ï¼ˆdogeï¼‰ã€‚","link":"/life/canada-visa/"},{"title":"ç¬¬ä¸€ä¸ªç”Ÿæ´»ç¯‡","text":"æœ€è¿‘åŒ—äº¬å¤©æ°”è¿˜å¯ä»¥, å¾ˆæœ‰æ˜¥å¤©çš„æ„æ€, ä»Šå¹´åŒ—äº¬æ²¡æœ‰åˆ®é»„æ²™æ»¡å¤©é£çš„æ²™å°˜ã€‚ä¸è¿‡æœ‰æ—¶å€™è§‰å¾—ä¸­åˆä¸‹åˆæ¯”è¾ƒçƒ­, æ—©ä¸Šå’Œæ™šä¸Šä¼šå†·ä¸€äº›, æ˜¼å¤œæ¸©å·®å¤§ã€‚","link":"/life/hello-world/"},{"title":"æ„å¤§åˆ©ç­¾è¯è®°","text":"è¿™æ˜¯ä¸€ä¸ªå¾ˆç³Ÿç³•çš„æ•…äº‹ã€‚ å’Œå­¦é•¿åˆä½œä¸­äº†eccv24ï¼Œå¯ä»¥å»æ„å¤§åˆ©ç±³å…°ï¼Œå…«æœˆä»½å¼€å§‹å‡†å¤‡ç­¾è¯ï¼Œæƒ³ç€åŒ—äº¬çº¦ä¸åˆ°slotçš„è¯å°±å»æ²ˆé˜³ã€‚å»äº†æ²ˆé˜³æ‰çŸ¥é“æ„å¤§åˆ©çš„ç­¾è¯æ˜¯åˆ†é¢†åŒºçš„ï¼Œç¬¦åˆé¢†åŒºèŒƒå›´çš„æ‰å¯ä»¥å»æ²ˆé˜³ã€‚ç¬¦åˆé¢†åŒºçš„æ¡ä»¶æ˜¯è¯æ˜ä½ æ˜¯åŒ—äº¬äººï¼Œå¯ä»¥é€šè¿‡ å±…ä½è¯ æˆ·å£ å­¦ç”Ÿçš„åœ¨è¯»è¯æ˜ ä»¥ä¸Šä¸‰ç‚¹æ¥è¯æ˜ã€‚ä½†æ˜¯å½¼æ—¶æˆ‘åˆšå…¥å­¦ï¼Œå­¦æ ¡è¦ä¸‰ä¸ªæœˆåæ‰èƒ½å¼€åœ¨è¯»è¯æ˜ï¼Œç„¶åæˆ‘å¹¶æ²¡æœ‰è¿ç§»é›†ä½“æˆ·å£ï¼Œæ‰€ä»¥ç›´æ¥ggäº†ã€‚ å†æƒ³ç€ç”³è¯·ä¸Šæµ·é¢†åŒºçš„slotå‘ç°å¼‚å¸¸æ‹¥æŒ¤ï¼Œé»„ç‰›ä¹Ÿéš¾æ‹¿åˆ°å·ï¼Œæœ€åä¸äº†äº†ä¹‹ï¼Œæ²¡å»æˆï¼Œé”™è¿‡äº†ä¸€åœºæ„‰å¿«çš„æ„å¤§åˆ©æ¬§æ´²ä¹‹æ—…ã€‚","link":"/life/italy-visa/"}],"tags":[{"name":"model arch","slug":"model-arch","link":"/tags/model-arch/"},{"name":"test","slug":"test","link":"/tags/test/"},{"name":"career","slug":"career","link":"/tags/career/"},{"name":"mlsys","slug":"mlsys","link":"/tags/mlsys/"}],"categories":[{"name":"blog","slug":"blog","link":"/blog/"},{"name":"life","slug":"life","link":"/life/"}],"pages":[{"title":"Chendong Xiang(é¡¹æ™¨ä¸œ)","text":"BiographyI am a undergraduate student of computer science at Tsinghua University. I am going to join the TSAIL Group in the Department of Computer Science and Technology, Tsinghua University, advised by Prof. Jun Zhu. Currently, my research interest includes topics on deep generative models, including diffusion models, and their applications in computer vision, 3D generation and. I also interested in embodied AI and machine learning system. Publications FeedFace: Efficient Inference-based Face Personalization via Diffusion Models Chendong Xiang, Armando Fortes, Khang Hui Chua, Hang Su, Jun Zhu International Conference on Learning Representations (ICLR2024) [code] CRM: Single Image to 3D Textured Mesh with Convolutional Reconstruction Model Zhengyi Wang, Yikai Wang, Yifei Chen, Chendong Xiang, Shuo Chen, Dajiang Yu, Chongxuan Li, Hang Su, Jun Zhu (ECCV2024) [code] Identifying and Solving Conditional Image Leakage in Image to-Video Generation Min Zhao*, Hongzhou Zhu*, Chendong Xiang, Kaiwen Zheng, Chongxuan Li, Jun Zhu (NeurIPs2024) [code] / [website] Preprints A Closer Look at Parameter-Efficient Tuning in Diffusion Models Chendong Xiang, Fan Bao, Chongxuan Li, Hang Su, Jun Zhu [code] Vidu: a Highly Consistent, Dynamic and Skilled Text-to-Video Generator with Diffusion Models Fan Bao, Chendong Xiang*, Gang Yue*, Guande He*, Hongzhou Zhu*, Kaiwen Zheng*, Min Zhao*, Shilong Liu*, Yaole Wang*, Jun Zhu SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference Jintao Zhang, Chendong Xiang, Haofeng Huang, Haocheng Xi, Jia Wei, Jun Zhu, Jianfei Chen [code] Competitions International Algorithm Case Competition(IACC), Champion, 2023.12 Computer System Development Capability Competition, OS functional design, First Prize, 2022.8 ACM-China International Parallel Computing Challengeï¼ˆIPCCï¼‰, Third Prize(Fourth place), 2022.10 Chinese Chemistry Olympiadï¼ˆCChOï¼‰, Gold Medal, 2018 Honors &amp; Awards Science and Technology Innovation Excellent Scholarship, Tsinghua University, 2022 Excellent Volunteer Scholarship, Tsinghua University, 2022 Literary and Arts Excellence Scholarship, Tsinghua University, 2021, 2020 National Encouragement Scholarship, 2020","link":"/cv.html"},{"title":"Chendong Xiang","text":"ğŸ‘‹ Hi, Iâ€™m Chendong Xiang, you could also call me Xiaoyu Xiangï¼Œan Fist-year PHD student at THU CSTğŸ‘€ Iâ€™m interested in generative model and embodied AIğŸŒ± Iâ€™m currently learning pretrain model, such as t2i diffusion modelsğŸ’ï¸ Iâ€™m looking to collaborate on AI projectsğŸ“« How to reach me xcd19@mails.tsinghua.edu.cn","link":"/index.html"}]}